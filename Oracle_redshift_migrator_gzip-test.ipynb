{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cx_Oracle\n",
    "import pandas as pd\n",
    "import configparser\n",
    "import sys\n",
    "import boto3\n",
    "import psycopg2\n",
    "import traceback\n",
    "import datetime\n",
    "import gzip\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeit(method):\n",
    "    def timed(*args, **kw):\n",
    "        ts = time.time()\n",
    "        result = method(*args, **kw)\n",
    "        te = time.time()\n",
    "        print('%r (%r, %r) %2.2f sec' %(method.__name__, args, kw, te-ts))\n",
    "        return result\n",
    "    return timed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def config_unpacker(config_file):\n",
    "    time.sleep(5)\n",
    "    try:\n",
    "        config = configparser.RawConfigParser()\n",
    "        config.read(config_file)\n",
    "        credentials = {key: value for key, value in config._sections['Credentials'].items() if not key.startswith(\"__\")}\n",
    "        return(credentials)\n",
    "    except Exception as e:\n",
    "        print(\"Error reading Config file :{}\".format(e))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql_generator():\n",
    "    db_info_loc = r\"./Inputs/db_info.csv\"\n",
    "    df = pd.read_csv(db_info_loc)\n",
    "\n",
    "    def sql(row):\n",
    "        string = f\"select * from {row['table_name']} where to_char({row['Column_name']}, 'yyyy') like {row['Year']}\"\n",
    "        return(string)\n",
    "\n",
    "    df['sql'] = df.apply(lambda x: sql(x), axis  =1)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timeit\n",
    "def oracle_retrieve(table,config_file,config_unpacker):\n",
    "    #Asserting db credentials\n",
    "    def df_csv(reader):\n",
    "        print('In the loop')\n",
    "        i+=1\n",
    "        gzip_file = r'./Output/{}_{}.csv.gz'.format(table,i)\n",
    "        print(\"Writing to gzip file_{}\".format(i))\n",
    "        reader.to_csv(gzip_file,header=True,index=False,compression = 'gzip')\n",
    "    conn_dict = config_unpacker(config_file)\n",
    "    try:\n",
    "        connection = cx_Oracle.connect(user=conn_dict['user'], password=conn_dict['pwd'], dsn=cx_Oracle.makedsn(conn_dict['host'],conn_dict['port'],conn_dict['sid']))\n",
    "    except cx_Oracle.DatabaseError as e:\n",
    "        print('Database connection error: {}'.format(e))    \n",
    "        sys.exit(\"Failed establishing connection to given database\")\n",
    "    else:\n",
    "        with connection:     \n",
    "            print(\"Connection established with database\")\n",
    "            sql_query = \"select * from {} where ROWNUM <= 40000\".format(table)\n",
    "            try:\n",
    "                print(\"Loading to datafarame\")\n",
    "                reader = pd.read_sql(sql = sql_query,con = connection, chunksize = 4)\n",
    "                i = 0\n",
    "                try:    \n",
    "                    concurrent.futures.ProcessPoolExecutor.map(df_csv,reader)\n",
    "                except Exception as exec:\n",
    "                    print(f'Error occured in thereading ----{exec}')\n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "        print(\"Closing database Connection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copy to S3 bucket,\n",
    "def s3_copy(table_name):\n",
    "    bucket = '{}'.format(table_name)\n",
    "    s3_file = '.{} {}.csv'.format(table_name,time.strftime(\"_%d-%m-%Y-%H:%M:%S\"))\n",
    "\n",
    "    s3 = boto3.resource('s3')\n",
    "    s3.meta.client.upload_file(csv_file, bucket , s3_file)\n",
    "    return(list(bucket , s3_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copy to redshift\n",
    "def redshift_upload(aws_config,bucket,s3_file,config_unpacker):\n",
    "\n",
    "    file_path = 's3://{}/{}'.format(bucket,s3_file)\n",
    "\n",
    "    conn_string = \"dbname='{dbname}' port='{port}' user='{user}' password='{password}' host='{host_url}'\".format(**config_unpacker(aws_config))\n",
    "    copy_cmd =\"\"\"copy {schema}.{table} from '{file_path}' credentials 'aws_access_key_id={aws_access_key_id};aws_secret_access_key={aws_secret_access_key}' \\\n",
    "            commit;\"\"\".format(**config_unpacker(aws_config))\n",
    "\n",
    "    with psycopg2.connect(conn_string) as conn:\n",
    "        with conn.cursor() as curs:\n",
    "            curs.execute(copy_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    config_file = \"./config_file.cfg\"\n",
    "    aws_config = './aws_config'\n",
    "    table = \"case_f\"\n",
    "    \n",
    "    oracle_retrieve(table,config_file,config_unpacker) \n",
    "#     s3_args = s3_copy(table)\n",
    "#     redshift_upload(aws_config,*s3_args,config_unpacker())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-10-6640bd7335f2>\", line 3, in <module>\n",
      "    main()\n",
      "  File \"<ipython-input-9-d742a141a8f9>\", line 6, in main\n",
      "    oracle_retrieve(table,config_file,config_unpacker)\n",
      "  File \"<ipython-input-2-f29f7f7cf3ac>\", line 4, in timed\n",
      "    result = method(*args, **kw)\n",
      "  File \"<ipython-input-6-d3d850701108>\", line 12, in oracle_retrieve\n",
      "    connection = cx_Oracle.connect(user=conn_dict['user'], password=conn_dict['pwd'], dsn=cx_Oracle.makedsn(conn_dict['host'],conn_dict['port'],conn_dict['sid']))\n",
      "NameError: name 'conn_dict' is not defined\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        main()\n",
    "    except:\n",
    "        print(traceback.format_exc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection established with database\n",
      "Loading to datafarame\n",
      "__enter__\n",
      "Closing database Connection\n"
     ]
    }
   ],
   "source": [
    "config_file = \"./config_file.cfg\"\n",
    "aws_config = './aws_config'\n",
    "table = \"case_f\"\n",
    "conn_dict = config_unpacker(config_file)\n",
    "i = 0\n",
    "def df_csv(df):\n",
    "    global i\n",
    "    i+=1\n",
    "    print('In the function')\n",
    "    gzip_file = r'./Output/{}_{}.csv.gz'.format(table,i)\n",
    "    print(\"Writing to gzip file_{}\".format(i))\n",
    "    df.to_csv(gzip_file,header=True,index=False,compression = 'gzip')\n",
    "try:\n",
    "    connection = cx_Oracle.connect(user=conn_dict['user'], password=conn_dict['pwd'], dsn=cx_Oracle.makedsn(conn_dict['host'],conn_dict['port'],conn_dict['sid']))\n",
    "except cx_Oracle.DatabaseError as e:\n",
    "    print('Database connection error: {}'.format(e))    \n",
    "    sys.exit(\"Failed establishing connection to given database\")\n",
    "else:\n",
    "    with connection:     \n",
    "        print(\"Connection established with database\")\n",
    "        sql_query = \"select * from {} where ROWNUM <= 4000\".format(table)\n",
    "        try:\n",
    "            print(\"Loading to datafarame\")\n",
    "            reader = pd.read_sql(sql = sql_query,con = connection, chunksize = 1000)\n",
    "            with ThreadPoolExecutor as executor:\n",
    "                futures = executor.map(df_csv,reader)\n",
    "                for future in concurrent.futures.as_completed(futures):\n",
    "                    print(future)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "print(\"Closing database Connection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
